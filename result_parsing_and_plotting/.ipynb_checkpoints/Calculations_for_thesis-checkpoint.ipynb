{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 9000)\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set to False if no subsampling, else set to the desired number for subsample results:\n",
    "#subsampling = \"2\"\n",
    "subsampling = False\n",
    "\n",
    "\n",
    "\n",
    "#For a special case of looking only at samples with 200X coverage:\n",
    "#high_coverage_analysis = False\n",
    "high_coverage_analysis = False\n",
    "\n",
    "#Failsafe:\n",
    "if high_coverage_analysis == True:\n",
    "    subsampling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = 'C:\\\\Users\\\\nikol\\\\OneDrive\\\\DTU\\\\11_semester\\\\'\n",
    "\n",
    "resultpath = main_folder_path + '1000_genomes_results\\\\'\n",
    "\n",
    "#Outcomment all but the resolution desired:\n",
    "if subsampling != False:\n",
    "    resultpath = main_folder_path + 'output_' + subsampling + 'X\\\\' + '1000_genomes_results\\\\'\n",
    "\n",
    "gold_standard_path = main_folder_path + 'gold_standard_data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chose allele resolution: options: \"two_field\", \"g_group\" or \"p_group\" (or e_group)\n",
    "resolution = \"e_group\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Allele conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for converting an allele to four field resolution (disregarding any trailing letters - still unambiguous)\n",
    "\n",
    "def make_two_field(allele_high_res):\n",
    "    two_field_finder = re.search(r\"(A|B|C|DRB1|DQB1)\\*\\d{2}:\\d{2,3}\", allele_high_res)\n",
    "    \n",
    "    if two_field_finder != None:\n",
    "        allele_two_field = two_field_finder.group(0)\n",
    "    else:\n",
    "        allele_two_field = None\n",
    "    \n",
    "    return allele_two_field    \n",
    "\n",
    "\n",
    "def make_three_field(allele_high_res):\n",
    "    three_field_finder = re.search(r\"(A|B|C|DRB1|DQB1)\\*\\d{2}:\\d{2,3}:\\d{2,3}\", allele_high_res)\n",
    "    \n",
    "    if three_field_finder != None:\n",
    "        allele_three_field = three_field_finder.group(0)\n",
    "    else:\n",
    "        allele_three_field = None\n",
    "    \n",
    "    return allele_three_field     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for P-group conversion - THIS DICT IS SLIGHTLY DIFFERENT\n",
    "however, the function convert_to_p_type returns the same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dict for P-type conversion\n",
    "\n",
    "p_group_filepath = gold_standard_path + 'p_group_resolution.txt'\n",
    "\n",
    "p_group_dict = dict()\n",
    "\n",
    "#Read the important results:\n",
    "with open(p_group_filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        #If several alleles map to the same one, they are separated by a \"/\"\n",
    "#        if ('/' in line) and (line[0] != '#'):\n",
    "        if line[0] != '#':\n",
    "            gene = line.split('*')[0]\n",
    "            \n",
    "            #Only register the valid alleles:\n",
    "            if gene in ['A', 'B', 'C', 'DRB1', 'DQB1']:\n",
    "                \n",
    "                if \"/\" in line:\n",
    "                    p_group_full = gene + \"*\" + line.split(';')[-1][:-1]\n",
    "                else:\n",
    "                    p_group_full = gene + \"*\" + line.split(';')[-2]\n",
    "            \n",
    "                #Read the rest of the alleles and clean up the front and end part\n",
    "                synonymous_alleles = line.split('/')\n",
    "                synonymous_alleles[0] = synonymous_alleles[0].split(';')[1]\n",
    "                synonymous_alleles[-1] = synonymous_alleles[-1].split(';')[0]\n",
    "                \n",
    "                #Convert all alleles to four field resolution\n",
    "                for i in range(len(synonymous_alleles)):\n",
    "                    synonymous_alleles[i] = gene + \"*\" + synonymous_alleles[i]\n",
    "                    synonymous_alleles[i] = make_two_field(synonymous_alleles[i])\n",
    "                    \n",
    "                #Add the group itself to the list, so that tools predicting in G-type resolution can be converted in similar fashion\n",
    "                synonynous_alleles = synonymous_alleles.append(p_group_full)\n",
    "\n",
    "                #Remove duplicates when converting to four field:\n",
    "                synonymous_allels_unique_two_field = list(set(synonymous_alleles))\n",
    "                \n",
    "                #Add key in dict for each of the unique entries:\n",
    "                for synonymous_allele in synonymous_allels_unique_two_field:\n",
    "\n",
    "                    p_group_dict[synonymous_allele] = p_group_full\n",
    "                    \n",
    "\n",
    "#Make P type conversion function using p_group_dict\n",
    "def convert_to_p_group(allele):\n",
    "\n",
    "    #Start by converting to four field:\n",
    "    allele_two_field = make_two_field(allele)\n",
    "    \n",
    "    #Find corresponding P-type if it exists. If not, return the four field resolution\n",
    "    if allele_two_field in p_group_dict:\n",
    "        allele_two_field_p_group = p_group_dict[allele_two_field]\n",
    "    else:\n",
    "        allele_two_field_p_group = allele_two_field\n",
    "        \n",
    "    return allele_two_field_p_group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for G-group conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguities in two-field resolution:\n",
      "Allele\tPrimary G-group\tAlternative group\n",
      "two_field_res, A*02:01, A*02:01:01G, A*02:01:02G\n",
      "two_field_res, A*23:03, A*23:03:01, A*23:03:02G\n",
      "two_field_res, A*24:02, A*24:02:01G, A*24:02:115G\n",
      "two_field_res, A*24:208, A*24:208:01, A*24:208:02G\n",
      "two_field_res, A*29:02, A*29:02:01G, A*29:02:17G\n",
      "two_field_res, A*68:01, A*68:01:01G, A*68:01:02G\n",
      "two_field_res, B*15:16, B*15:16:01G, B*15:16:02G\n",
      "two_field_res, B*27:05, B*27:05:02G, B*27:05:18G\n",
      "two_field_res, B*38:02, B*38:02:01G, B*38:02:02G\n",
      "two_field_res, B*39:02, B*39:02:01G, B*39:02:02G\n",
      "two_field_res, B*39:06, B*39:06:01, B*39:06:02G\n",
      "two_field_res, B*40:01, B*40:01:01G, B*40:01:03G\n",
      "two_field_res, B*44:281, B*44:03:01G, B*44:03:02G\n",
      "two_field_res, B*44:03, B*44:03:01G, B*44:03:02G\n",
      "two_field_res, B*51:01, B*51:01:01G, B*51:01:02G\n",
      "two_field_res, B*52:01, B*52:01:01G, B*52:01:02G\n",
      "two_field_res, B*67:01, B*67:01:01, B*67:01:02G\n",
      "two_field_res, C*02:02, C*02:02:01, C*02:02:02G\n",
      "two_field_res, C*02:02, C*02:02:01, C*02:10:01G\n",
      "two_field_res, C*03:04, C*03:04:01G, C*03:04:02G\n",
      "two_field_res, C*03:35, C*03:35:01, C*03:35:02G\n",
      "two_field_res, C*06:04, C*06:04:01, C*06:04:02G\n",
      "two_field_res, C*07:01, C*07:01:01G, C*07:01:20G\n",
      "two_field_res, C*07:18, C*07:01:01G, C*07:01:58G\n",
      "two_field_res, C*07:01, C*07:01:01G, C*07:01:58G\n",
      "two_field_res, C*07:02, C*07:02:01G, C*07:02:36G\n",
      "two_field_res, C*07:02, C*07:02:01G, C*07:02:104G\n",
      "two_field_res, C*07:04, C*07:04:01G, C*07:04:02G\n",
      "two_field_res, C*12:03, C*12:03:01G, C*12:03:34G\n",
      "two_field_res, C*12:04, C*12:04:01, C*12:04:02G\n",
      "two_field_res, C*15:02, C*15:02:01G, C*15:02:02G\n",
      "two_field_res, C*15:02, C*15:02:01G, C*15:02:33G\n",
      "two_field_res, DQB1*03:03, DQB1*03:03:02G, DQB1*03:03:03G\n",
      "two_field_res, DQB1*03:10, DQB1*03:10:01G, DQB1*03:10:02G\n",
      "two_field_res, DQB1*06:99, DQB1*06:99:01, DQB1*06:99:02G\n",
      "two_field_res, DRB1*11:01, DRB1*11:01:01G, DRB1*11:01:02G\n",
      "two_field_res, DRB1*15:02, DRB1*15:02:01G, DRB1*15:02:02G\n"
     ]
    }
   ],
   "source": [
    "#Make dict for G-type conversion\n",
    "\n",
    "g_group_filepath = gold_standard_path + 'g_group_resolution.txt'\n",
    "\n",
    "g_group_dict = dict()\n",
    "\n",
    "\n",
    "#Make conversion from full allele names to G groups\n",
    "with open(g_group_filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        #If several alleles map to the same one, they are separated by a \"/\"\n",
    "        if line[0] != '#':\n",
    "            gene = line.split('*')[0]\n",
    "            \n",
    "            #Only register the valid alleles:\n",
    "            if gene in ['A', 'B', 'C', 'DRB1', 'DQB1']:\n",
    "                        \n",
    "                #find full G type for entry - differs depending on, whether there are 1 or multiple entries in the group.\n",
    "                if \"/\" in line:\n",
    "                    g_group_full = gene + \"*\" + line.split(';')[-1][:-1]\n",
    "                else:\n",
    "                    g_group_full = gene + \"*\" + line.split(';')[-2]\n",
    "\n",
    "                #For full dict (parallel to four-field dict)\n",
    "                #Read the rest of the alleles and clean up the front and end part\n",
    "                synonymous_alleles = line.split('/')\n",
    "                synonymous_alleles[0] = synonymous_alleles[0].split(';')[1]\n",
    "                synonymous_alleles[-1] = synonymous_alleles[-1].split(';')[0]\n",
    "                \n",
    "                #Add \"gene*\" in front of all alleles:\n",
    "                for i in range(len(synonymous_alleles)):\n",
    "                    synonymous_alleles[i] = gene + \"*\" + synonymous_alleles[i]\n",
    "                \n",
    "                #Add the group itself to the list, so that tools predicting in G-type resolution can be converted in similar fashion\n",
    "                synonynous_alleles = synonymous_alleles.append(g_group_full)\n",
    "                \n",
    "                #Remove duplicates\n",
    "                synonymous_allels_unique = sorted(list(set(synonymous_alleles)), reverse=True)\n",
    "                \n",
    "                #Add key in dict for each of the unique entries:\n",
    "                for allele in synonymous_allels_unique :                    \n",
    "                    g_group_dict[allele] = g_group_full\n",
    "\n",
    "\n",
    "                    \n",
    "print(\"Ambiguities in two-field resolution:\")\n",
    "print(\"Allele\", \"Primary G-group\", \"Alternative group\", sep = \"\\t\")\n",
    "#Add entries for 4-field and 6-field resolution typings, not already found in g_group_dict.\n",
    "#This is done after, in order to not overwrite ambiguous G-group mappings such as C*02:02,\n",
    "#which could map to C*02:02:01 or C*02:10:01G depending on the full typing.\n",
    "with open(g_group_filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        #If several alleles map to the same one, they are separated by a \"/\"\n",
    "        if line[0] != '#':\n",
    "            gene = line.split('*')[0]\n",
    "            \n",
    "            #Only register the valid alleles:\n",
    "            if gene in ['A', 'B', 'C', 'DRB1', 'DQB1']:                \n",
    "                \n",
    "                if \"/\" in line:\n",
    "                    g_group_full = gene + \"*\" + line.split(';')[-1][:-1]\n",
    "                else:\n",
    "                    g_group_full = gene + \"*\" + line.split(';')[-2]\n",
    "\n",
    "                #Add to four field dict (Parralel to the full dict)\n",
    "                synonymous_alleles_two_field = line.split('/')\n",
    "                synonymous_alleles_two_field[0] = synonymous_alleles_two_field[0].split(';')[1]\n",
    "                synonymous_alleles_two_field[-1] = synonymous_alleles_two_field[-1].split(';')[0]\n",
    "                                \n",
    "                #Convert all alleles to four field resolution for four field typing:\n",
    "                for i in range(len(synonymous_alleles_two_field)):\n",
    "                    synonymous_alleles_two_field[i] = gene + \"*\" + synonymous_alleles_two_field[i]\n",
    "                    synonymous_alleles_two_field[i] = make_two_field(synonymous_alleles_two_field[i])\n",
    "\n",
    "                #Remove duplicates when converting to four field:\n",
    "                synonymous_allels_unique_two_field = sorted(list(set(synonymous_alleles_two_field)), reverse=True)\n",
    "                \n",
    "                #Add key in dict for each of the unique entries:\n",
    "                for allele in synonymous_allels_unique_two_field:                    \n",
    "                    \n",
    "                    #Only add entries, which aren't already in the dict\n",
    "                    if (allele in g_group_dict.keys()):\n",
    "                        \n",
    "                        #For two-field: Check for ambiguities in the G-type conversion e.g. C*02:02:02G and C*02:10:01G have same exon sequence for exon 2 and 3\n",
    "                        #Print the ambiguity - because of sort, nothing is added. two-field-typed-allele is kept in the group\n",
    "                        if (g_group_dict[allele] != g_group_full) and (\"/\" in line):\n",
    "                            print(\"two_field_res\", allele, g_group_dict[allele], g_group_full, sep=', ')\n",
    "                            \n",
    "                    else:\n",
    "                        g_group_dict[allele] = g_group_full\n",
    "                \n",
    "                #Add to six field dict (Parralel to the full dict)\n",
    "                synonymous_alleles_three_field = line.split('/')\n",
    "                synonymous_alleles_three_field[0] = synonymous_alleles_three_field[0].split(';')[1]\n",
    "                synonymous_alleles_three_field[-1] = synonymous_alleles_three_field[-1].split(';')[0]\n",
    "                \n",
    "                  #Convert all alleles to six field resolution for six field typing:\n",
    "                for i in range(len(synonymous_alleles_three_field)):\n",
    "                    synonymous_alleles_three_field[i] = gene + \"*\" + synonymous_alleles_three_field[i]\n",
    "                    synonymous_alleles_three_field[i] = make_three_field(synonymous_alleles_three_field[i])\n",
    "                    \n",
    "                \n",
    "                synonymous_alleles_three_field = [i for i in synonymous_alleles_three_field if i != None]\n",
    "                #Remove duplicates when converting to six field:\n",
    "                synonymous_allels_unique_three_field = sorted(list(set(synonymous_alleles_three_field)), reverse=True)\n",
    "                \n",
    "                #Add key in dict for each of the unique entries:\n",
    "                for allele in synonymous_allels_unique_three_field:                    \n",
    "                    \n",
    "                    #Only add entries, which aren't already in the dict\n",
    "                    if (allele in g_group_dict.keys()):\n",
    "                        \n",
    "                        #For six-field: Check for ambiguities in the G-type conversion e.g. C*02:02:02G and C*02:10:01G have same exon sequence for exon 2 and 3\n",
    "                        #Print the ambiguity - because of sort, nothing is added. six-field-typed-allele is kept in the group\n",
    "                        if (g_group_dict[allele] != g_group_full) and (\"/\" in line):\n",
    "                            print(\"three_field_res:\", allele, g_group_dict[allele], g_group_full, sep=', ')\n",
    "                            \n",
    "                    else:\n",
    "                        g_group_dict[allele] = g_group_full\n",
    "\n",
    "                \n",
    "                \n",
    "                    \n",
    "#Make G type conversion function using g_group_dict\n",
    "def convert_to_g_group(allele):\n",
    "\n",
    "    if allele in g_group_dict.keys():\n",
    "        allele_g_group = g_group_dict[allele]\n",
    "    else:\n",
    "        allele_g_group = make_two_field(allele)\n",
    "        \n",
    "    return allele_g_group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaxion typing resolution\n",
    "Using Evaxion typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make dict for G-type conversion\n",
    "\n",
    "e_group_filepath = gold_standard_path + 'e_group_resolution.txt'\n",
    "\n",
    "e_group_dict = dict()\n",
    "\n",
    "\n",
    "#Make conversion from full allele names to G groups\n",
    "with open(e_group_filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        if line.startswith('HLA-'):\n",
    "            gene = line[4]\n",
    "            \n",
    "            if gene in ['A', 'B', 'C']:     \n",
    "                \n",
    "                \n",
    "                digits_from_type = re.search(r'\\d{2}:\\d{2,3}',line)\n",
    "                \n",
    "                if digits_from_type != None:\n",
    "                    allele = gene + \"*\" + digits_from_type.group(0)\n",
    "\n",
    "                    peptide_sequence = line.split('\\t')[-1][:-1]\n",
    "\n",
    "                    e_group_dict[allele] = peptide_sequence\n",
    "                    \n",
    "\n",
    "            \n",
    "        elif line.startswith('DRB1'):\n",
    "            gene = 'DRB1'\n",
    "            \n",
    "            digits_from_type_raw = line.split('_')[1].split('\\t')[0]\n",
    "            \n",
    "            digits_from_type = digits_from_type_raw[0:2] + ':' + digits_from_type_raw[2:]\n",
    "            \n",
    "            allele = gene + \"*\" + digits_from_type\n",
    "                \n",
    "            peptide_sequence = line.split('\\t')[-1][:-1]\n",
    "            \n",
    "            e_group_dict[allele] = peptide_sequence\n",
    "            \n",
    "\n",
    "#Function for converting to e-group resolution:\n",
    "#Make E type conversion function using e_group_dict\n",
    "def convert_to_e_group(allele):\n",
    "\n",
    "    #Start by converting to four field:\n",
    "    allele_two_field = make_two_field(allele)\n",
    "    \n",
    "    #Find corresponding e-type if it exists. If not, return the P resolution\n",
    "    if allele_two_field in e_group_dict:\n",
    "        allele_e_group = e_group_dict[allele_two_field]\n",
    "    else:\n",
    "        allele_e_group = convert_to_p_group(allele_two_field)\n",
    "        #print(allele_two_field)\n",
    "        \n",
    "    return allele_e_group\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations \n",
    "\n",
    "Number of alleles:\n",
    "\n",
    "- two field: 16621\n",
    "- G group: 18483\n",
    "- overlap between G group and two field: 12151 \n",
    "- P group: 14001\n",
    "- Evaxion group: 12433"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of two-field alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16621"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assume, that the g_group dict contains all known alleles - the unique keys converted to two field\n",
    "#Would then be all the known two field alleles\n",
    "0\n",
    "g_group_keys = list(g_group_dict.keys())\n",
    "len(list(set([make_two_field(i) for i in g_group_keys])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of G groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18483"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculation of total G groups (taken from .txt file - http://hla.alleles.org/alleles/g_groups.html: )\n",
    "#A, B and C - starting_lines + DQB1 + DRB1\n",
    "14871-6+1228+2390\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18483"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check with g_group_dict:\n",
    "g_group_values = list(g_group_dict.values())\n",
    "len(list(set(g_group_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explanation as to why, there are more G groups than two-field alleles: These are all the G-groups mapping to A*01:01\n",
    "a_0101_list = ['A*01:01:01G', 'A*01:01:02', 'A*01:01:03', 'A*01:01:04', 'A*01:01:05', 'A*01:01:06', 'A*01:01:07', 'A*01:01:08', 'A*01:01:09', 'A*01:01:10', 'A*01:01:101', 'A*01:01:102', 'A*01:01:107', 'A*01:01:109', 'A*01:01:11', 'A*01:01:110', 'A*01:01:111', 'A*01:01:112', 'A*01:01:113', 'A*01:01:114', 'A*01:01:117', 'A*01:01:119', 'A*01:01:12', 'A*01:01:120', 'A*01:01:13', 'A*01:01:14', 'A*01:01:15', 'A*01:01:16', 'A*01:01:17', 'A*01:01:18', 'A*01:01:19', 'A*01:01:20', 'A*01:01:21', 'A*01:01:22', 'A*01:01:23', 'A*01:01:24', 'A*01:01:25', 'A*01:01:26', 'A*01:01:27', 'A*01:01:28', 'A*01:01:29', 'A*01:01:30', 'A*01:01:31', 'A*01:01:32', 'A*01:01:33', 'A*01:01:34', 'A*01:01:35', 'A*01:01:36', 'A*01:01:37', 'A*01:01:39', 'A*01:01:40', 'A*01:01:41', 'A*01:01:42', 'A*01:01:43', 'A*01:01:44', 'A*01:01:45', 'A*01:01:46', 'A*01:01:47', 'A*01:01:48', 'A*01:01:49', 'A*01:01:50', 'A*01:01:52', 'A*01:01:53', 'A*01:01:54', 'A*01:01:55', 'A*01:01:56', 'A*01:01:57', 'A*01:01:58', 'A*01:01:59', 'A*01:01:60', 'A*01:01:61', 'A*01:01:62', 'A*01:01:63', 'A*01:01:64', 'A*01:01:65', 'A*01:01:66', 'A*01:01:67', 'A*01:01:68', 'A*01:01:69', 'A*01:01:70', 'A*01:01:71', 'A*01:01:72', 'A*01:01:73', 'A*01:01:74', 'A*01:01:75', 'A*01:01:76', 'A*01:01:77', 'A*01:01:78', 'A*01:01:79', 'A*01:01:80', 'A*01:01:81', 'A*01:01:82', 'A*01:01:85', 'A*01:01:86', 'A*01:01:87', 'A*01:01:88', 'A*01:01:89', 'A*01:01:90', 'A*01:01:92', 'A*01:01:96', 'A*01:01:97', 'A*01:01:98', 'A*01:01:99']\n",
    "len(a_0101_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alleles belonging to A*01:01:01G\n",
    "a_0101G_list = [\"A*01:01:01:01\", \"A*01:01:01:02N\", \"A*01:01:01:03\", \"A*01:01:01:04\", \"A*01:01:01:05\", \"A*01:01:01:06\", \"A*01:01:01:07\", \"A*01:01:01:08\", \"A*01:01:01:09\", \"A*01:01:01:10\", \"A*01:01:01:11\", \"A*01:01:01:12\", \"A*01:01:01:13\", \"A*01:01:01:14\", \"A*01:01:01:15\", \"A*01:01:01:16\", \"A*01:01:01:17\", \"A*01:01:01:18\", \"A*01:01:01:19\", \"A*01:01:01:20\", \"A*01:01:01:21\", \"A*01:01:01:22\", \"A*01:01:01:23\", \"A*01:01:01:24\", \"A*01:01:01:25\", \"A*01:01:01:26\", \"A*01:01:01:27\", \"A*01:01:01:28\", \"A*01:01:01:29\", \"A*01:01:01:30\", \"A*01:01:01:31\", \"A*01:01:01:32\", \"A*01:01:01:33\", \"A*01:01:01:34\", \"A*01:01:01:35\", \"A*01:01:01:36\", \"A*01:01:01:37\", \"A*01:01:01:38\", \"A*01:01:01:39\", \"A*01:01:01:40\", \"A*01:01:01:41\", \"A*01:01:01:42\", \"A*01:01:01:43\", \"A*01:01:01:44\", \"A*01:01:01:45\", \"A*01:01:01:46\", \"A*01:01:01:47\", \"A*01:01:01:48\", \"A*01:01:01:49\", \"A*01:01:01:50\", \"A*01:01:01:51\", \"A*01:01:01:52\", \"A*01:01:01:53\", \"A*01:01:01:54\", \"A*01:01:01:55\", \"A*01:01:01:56\", \"A*01:01:01:57\", \"A*01:01:01:58\", \"A*01:01:01:59\", \"A*01:01:01:60\", \"A*01:01:01:61\", \"A*01:01:01:62\", \"A*01:01:38L\", \"A*01:01:51\", \"A*01:01:83\", \"A*01:01:84\", \"A*01:01:91\", \"A*01:01:93\", \"A*01:01:94\", \"A*01:01:95\", \"A*01:01:100\", \"A*01:01:103\", \"A*01:01:104\", \"A*01:01:105\", \"A*01:01:106\", \"A*01:01:108\", \"A*01:01:115\", \"A*01:01:116\", \"A*01:01:118\", \"A*01:04:01:01N\", \"A*01:04:01:02N\", \"A*01:22N\", \"A*01:32\", \"A*01:37:01:01\", \"A*01:37:01:02\", \"A*01:45\", \"A*01:56N\", \"A*01:81\", \"A*01:87N\", \"A*01:103\", \"A*01:107\", \"A*01:109\", \"A*01:132\", \"A*01:141\", \"A*01:142\", \"A*01:155\", \"A*01:177\", \"A*01:212\", \"A*01:217\", \"A*01:234\", \"A*01:237\", \"A*01:246\", \"A*01:248Q\", \"A*01:249\", \"A*01:251\", \"A*01:252\", \"A*01:253\", \"A*01:261\", \"A*01:274\", \"A*01:276\", \"A*01:277\", \"A*01:280\", \"A*01:281Q\", \"A*01:288\", \"A*01:291\", \"A*01:295\", \"A*01:296\", \"A*01:297\", \"A*01:300\", \"A*01:305\", \"A*01:306\", \"A*01:309\", \"A*01:316\", \"A*01:317\", \"A*01:319\", \"A*01:323\", \"A*01:324\", \"A*01:325\", \"A*01:328N\", \"A*01:331N\", \"A*01:332\", \"A*01:346\", \"A*01:347\", \"A*01:349\", \"A*01:351\", \"A*01:353\"]\n",
    "len(a_0101G_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alleles belonging to A*01:01:01G\n",
    "a_0101G_diff_from_2_field_list = [\"A*01:01:01:01\", \"A*01:04:01:01N\", \"A*01:22N\", \"A*01:32\", \"A*01:37:01:01\", \"A*01:45\", \"A*01:56N\", \"A*01:81\", \"A*01:87N\", \"A*01:103\", \"A*01:107\", \"A*01:109\", \"A*01:132\", \"A*01:141\", \"A*01:142\", \"A*01:155\", \"A*01:177\", \"A*01:212\", \"A*01:217\", \"A*01:234\", \"A*01:237\", \"A*01:246\", \"A*01:248Q\", \"A*01:249\", \"A*01:251\", \"A*01:252\", \"A*01:253\", \"A*01:261\", \"A*01:274\", \"A*01:276\", \"A*01:277\", \"A*01:280\", \"A*01:281Q\", \"A*01:288\", \"A*01:291\", \"A*01:295\", \"A*01:296\", \"A*01:297\", \"A*01:300\", \"A*01:305\", \"A*01:306\", \"A*01:309\", \"A*01:316\", \"A*01:317\", \"A*01:319\", \"A*01:323\", \"A*01:324\", \"A*01:325\", \"A*01:328N\", \"A*01:331N\", \"A*01:332\", \"A*01:346\", \"A*01:347\", \"A*01:349\", \"A*01:351\", \"A*01:353\"]\n",
    "len(a_0101G_diff_from_2_field_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A*01:01:11'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_g_group('A*01:01:11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of P group alleles\n",
    "The way I made the P group conversion was different from the G-group, as I didn't include the two-field resolutions, which didn't map to a P group (i.e. they made up their own P group) in the dict.\n",
    "I therefore take all the alleles (g_group_values) and run it through convert_to_p_group(i) and then take unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13203"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From P_group file (http://hla.alleles.org/alleles/p_groups.html)\n",
    "#A, B and C - starting_lines + DQB1 + DRB1\n",
    "10623-6+842+1744\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13203"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(p_group_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_p_alleles_set = set()\n",
    "for allele in list(set(g_group_values)):\n",
    "    \n",
    "    unique_p_alleles_set.add(convert_to_p_group(allele))\n",
    "\n",
    "len(list(unique_p_alleles_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A*01:11',\n",
       " 'A*01:123',\n",
       " 'A*01:15',\n",
       " 'A*01:16',\n",
       " 'A*01:160',\n",
       " 'A*01:162',\n",
       " 'A*01:178',\n",
       " 'A*01:179',\n",
       " 'A*01:18',\n",
       " 'A*01:186',\n",
       " 'A*01:240',\n",
       " 'A*01:247',\n",
       " 'A*01:250',\n",
       " 'A*01:258',\n",
       " 'A*01:269',\n",
       " 'A*01:27',\n",
       " 'A*01:285',\n",
       " 'A*01:290',\n",
       " 'A*01:293',\n",
       " 'A*01:308',\n",
       " 'A*01:31',\n",
       " 'A*01:320',\n",
       " 'A*01:326',\n",
       " 'A*01:336',\n",
       " 'A*01:52',\n",
       " 'A*01:53',\n",
       " 'A*01:57',\n",
       " 'A*02:113',\n",
       " 'A*02:125',\n",
       " 'A*02:222',\n",
       " 'A*02:223',\n",
       " 'A*02:225',\n",
       " 'A*02:226',\n",
       " 'A*02:227',\n",
       " 'A*02:250',\n",
       " 'A*02:284',\n",
       " 'A*02:301',\n",
       " 'A*02:314',\n",
       " 'A*02:32',\n",
       " 'A*02:321',\n",
       " 'A*02:350',\n",
       " 'A*02:366',\n",
       " 'A*02:373',\n",
       " 'A*02:395',\n",
       " 'A*02:439',\n",
       " 'A*02:468',\n",
       " 'A*02:476',\n",
       " 'A*02:490',\n",
       " 'A*02:501',\n",
       " 'A*02:514',\n",
       " 'A*02:516',\n",
       " 'A*02:525',\n",
       " 'A*02:53',\n",
       " 'A*02:540',\n",
       " 'A*02:622',\n",
       " 'A*02:643',\n",
       " 'A*02:696',\n",
       " 'A*02:715',\n",
       " 'A*02:748',\n",
       " 'A*02:773',\n",
       " 'A*02:775',\n",
       " 'A*02:788',\n",
       " 'A*02:789',\n",
       " 'A*02:796',\n",
       " 'A*02:797',\n",
       " 'A*02:803',\n",
       " 'A*02:806',\n",
       " 'A*02:807',\n",
       " 'A*02:82',\n",
       " 'A*02:831',\n",
       " 'A*02:833',\n",
       " 'A*02:858',\n",
       " 'A*02:879',\n",
       " 'A*02:88',\n",
       " 'A*02:880',\n",
       " 'A*02:887',\n",
       " 'A*02:895',\n",
       " 'A*02:94',\n",
       " 'A*02:945',\n",
       " 'A*02:946',\n",
       " 'A*03:03',\n",
       " 'A*03:11',\n",
       " 'A*03:161',\n",
       " 'A*03:168',\n",
       " 'A*03:178',\n",
       " 'A*03:192',\n",
       " 'A*03:197',\n",
       " 'A*03:262',\n",
       " 'A*03:266',\n",
       " 'A*03:269',\n",
       " 'A*03:275',\n",
       " 'A*03:283',\n",
       " 'A*03:284',\n",
       " 'A*03:286',\n",
       " 'A*03:297',\n",
       " 'A*03:323',\n",
       " 'A*03:329',\n",
       " 'A*03:330',\n",
       " 'A*03:334',\n",
       " 'A*03:335',\n",
       " 'A*03:337',\n",
       " 'A*03:342',\n",
       " 'A*03:357',\n",
       " 'A*03:36',\n",
       " 'A*03:364',\n",
       " 'A*03:381',\n",
       " 'A*03:68',\n",
       " 'A*03:69',\n",
       " 'A*03:91',\n",
       " 'A*11:109',\n",
       " 'A*11:115',\n",
       " 'A*11:127',\n",
       " 'A*11:137',\n",
       " 'A*11:180',\n",
       " 'A*11:208',\n",
       " 'A*11:215',\n",
       " 'A*11:238',\n",
       " 'A*11:251',\n",
       " 'A*11:287',\n",
       " 'A*11:310',\n",
       " 'A*11:340',\n",
       " 'A*11:78',\n",
       " 'A*11:99',\n",
       " 'A*23:08',\n",
       " 'A*23:106',\n",
       " 'A*23:108',\n",
       " 'A*23:11',\n",
       " 'A*23:19',\n",
       " 'A*23:38',\n",
       " 'A*23:84',\n",
       " 'A*24:132',\n",
       " 'A*24:158',\n",
       " 'A*24:185',\n",
       " 'A*24:222',\n",
       " 'A*24:232',\n",
       " 'A*24:240',\n",
       " 'A*24:252',\n",
       " 'A*24:278',\n",
       " 'A*24:303',\n",
       " 'A*24:312',\n",
       " 'A*24:323',\n",
       " 'A*24:357',\n",
       " 'A*24:359',\n",
       " 'A*24:36',\n",
       " 'A*24:370',\n",
       " 'A*24:389',\n",
       " 'A*24:396',\n",
       " 'A*24:408',\n",
       " 'A*24:425',\n",
       " 'A*24:426',\n",
       " 'A*24:428',\n",
       " 'A*24:429',\n",
       " 'A*24:433',\n",
       " 'A*24:434',\n",
       " 'A*24:435',\n",
       " 'A*24:445',\n",
       " 'A*24:45',\n",
       " 'A*24:456',\n",
       " 'A*24:467',\n",
       " 'A*24:48',\n",
       " 'A*24:514',\n",
       " 'A*24:60',\n",
       " 'A*24:84',\n",
       " 'A*24:86',\n",
       " 'A*24:90',\n",
       " 'A*25:12',\n",
       " 'A*25:42',\n",
       " 'A*25:49',\n",
       " 'A*25:69',\n",
       " 'A*26:107',\n",
       " 'A*26:11',\n",
       " 'A*26:127',\n",
       " 'A*26:145',\n",
       " 'A*26:161',\n",
       " 'A*26:206',\n",
       " 'A*26:25',\n",
       " 'A*26:60',\n",
       " 'A*26:71',\n",
       " 'A*29:08',\n",
       " 'A*29:112',\n",
       " 'A*29:78',\n",
       " 'A*30:121',\n",
       " 'A*30:123',\n",
       " 'A*30:145',\n",
       " 'A*30:158',\n",
       " 'A*30:178',\n",
       " 'A*30:27',\n",
       " 'A*30:59',\n",
       " 'A*30:70',\n",
       " 'A*30:73',\n",
       " 'A*30:76',\n",
       " 'A*30:78',\n",
       " 'A*31:126',\n",
       " 'A*31:131',\n",
       " 'A*31:141',\n",
       " 'A*31:149',\n",
       " 'A*31:158',\n",
       " 'A*31:60',\n",
       " 'A*32:112',\n",
       " 'A*32:126',\n",
       " 'A*32:130',\n",
       " 'A*32:132',\n",
       " 'A*32:133',\n",
       " 'A*32:135',\n",
       " 'A*32:19',\n",
       " 'A*32:27',\n",
       " 'A*32:45',\n",
       " 'A*32:48',\n",
       " 'A*32:56',\n",
       " 'A*32:92',\n",
       " 'A*33:123',\n",
       " 'A*33:140',\n",
       " 'A*33:143',\n",
       " 'A*33:154',\n",
       " 'A*33:176',\n",
       " 'A*33:194',\n",
       " 'A*33:198',\n",
       " 'A*33:80',\n",
       " 'A*33:96',\n",
       " 'A*34:10',\n",
       " 'A*66:27',\n",
       " 'A*66:39',\n",
       " 'A*68:120',\n",
       " 'A*68:142',\n",
       " 'A*68:171',\n",
       " 'A*68:18',\n",
       " 'A*68:181',\n",
       " 'A*68:182',\n",
       " 'A*68:199',\n",
       " 'A*68:203',\n",
       " 'A*68:205',\n",
       " 'A*68:210',\n",
       " 'A*68:213',\n",
       " 'A*68:236',\n",
       " 'A*68:245',\n",
       " 'A*68:251',\n",
       " 'A*68:49',\n",
       " 'A*68:59',\n",
       " 'A*68:94',\n",
       " 'A*74:12',\n",
       " 'A*74:14',\n",
       " 'A*74:32',\n",
       " 'B*07:111',\n",
       " 'B*07:135',\n",
       " 'B*07:167',\n",
       " 'B*07:181',\n",
       " 'B*07:182',\n",
       " 'B*07:201',\n",
       " 'B*07:231',\n",
       " 'B*07:251',\n",
       " 'B*07:272',\n",
       " 'B*07:285',\n",
       " 'B*07:315',\n",
       " 'B*07:316',\n",
       " 'B*07:318',\n",
       " 'B*07:325',\n",
       " 'B*07:343',\n",
       " 'B*07:351',\n",
       " 'B*07:386',\n",
       " 'B*07:67',\n",
       " 'B*08:08',\n",
       " 'B*08:148',\n",
       " 'B*08:214',\n",
       " 'B*08:215',\n",
       " 'B*08:220',\n",
       " 'B*08:252',\n",
       " 'B*08:30',\n",
       " 'B*08:67',\n",
       " 'B*08:72',\n",
       " 'B*08:82',\n",
       " 'B*08:86',\n",
       " 'B*13:07',\n",
       " 'B*13:103',\n",
       " 'B*13:137',\n",
       " 'B*13:49',\n",
       " 'B*13:56',\n",
       " 'B*13:63',\n",
       " 'B*13:76',\n",
       " 'B*14:07',\n",
       " 'B*14:41',\n",
       " 'B*14:72',\n",
       " 'B*14:79',\n",
       " 'B*15:111',\n",
       " 'B*15:149',\n",
       " 'B*15:181',\n",
       " 'B*15:182',\n",
       " 'B*15:190',\n",
       " 'B*15:209',\n",
       " 'B*15:226',\n",
       " 'B*15:246',\n",
       " 'B*15:258',\n",
       " 'B*15:26',\n",
       " 'B*15:262',\n",
       " 'B*15:272',\n",
       " 'B*15:294',\n",
       " 'B*15:304',\n",
       " 'B*15:375',\n",
       " 'B*15:400',\n",
       " 'B*15:454',\n",
       " 'B*15:463',\n",
       " 'B*15:496',\n",
       " 'B*15:528',\n",
       " 'B*15:540',\n",
       " 'B*15:544',\n",
       " 'B*15:549',\n",
       " 'B*15:562',\n",
       " 'B*15:79',\n",
       " 'B*15:94',\n",
       " 'B*18:138',\n",
       " 'B*18:154',\n",
       " 'B*18:182',\n",
       " 'B*18:23',\n",
       " 'B*18:74',\n",
       " 'B*18:94',\n",
       " 'B*27:176',\n",
       " 'B*27:223',\n",
       " 'B*27:225',\n",
       " 'B*27:59',\n",
       " 'B*27:64',\n",
       " 'B*27:65',\n",
       " 'B*27:66',\n",
       " 'B*27:94',\n",
       " 'B*35:129',\n",
       " 'B*35:130',\n",
       " 'B*35:145',\n",
       " 'B*35:165',\n",
       " 'B*35:173',\n",
       " 'B*35:216',\n",
       " 'B*35:381',\n",
       " 'B*35:427',\n",
       " 'B*35:430',\n",
       " 'B*35:453',\n",
       " 'B*35:461',\n",
       " 'B*35:53',\n",
       " 'B*37:03',\n",
       " 'B*37:30',\n",
       " 'B*37:33',\n",
       " 'B*37:42',\n",
       " 'B*37:79',\n",
       " 'B*37:82',\n",
       " 'B*38:165',\n",
       " 'B*38:34',\n",
       " 'B*38:83',\n",
       " 'B*39:116',\n",
       " 'B*39:133',\n",
       " 'B*39:139',\n",
       " 'B*39:142',\n",
       " 'B*39:146',\n",
       " 'B*39:147',\n",
       " 'B*39:157',\n",
       " 'B*39:161',\n",
       " 'B*39:25',\n",
       " 'B*39:40',\n",
       " 'B*39:87',\n",
       " 'B*39:95',\n",
       " 'B*39:97',\n",
       " 'B*40:118',\n",
       " 'B*40:142',\n",
       " 'B*40:155',\n",
       " 'B*40:216',\n",
       " 'B*40:22',\n",
       " 'B*40:256',\n",
       " 'B*40:263',\n",
       " 'B*40:265',\n",
       " 'B*40:286',\n",
       " 'B*40:291',\n",
       " 'B*40:337',\n",
       " 'B*40:345',\n",
       " 'B*40:361',\n",
       " 'B*40:372',\n",
       " 'B*40:399',\n",
       " 'B*40:426',\n",
       " 'B*40:428',\n",
       " 'B*40:438',\n",
       " 'B*41:45',\n",
       " 'B*44:108',\n",
       " 'B*44:149',\n",
       " 'B*44:171',\n",
       " 'B*44:195',\n",
       " 'B*44:198',\n",
       " 'B*44:217',\n",
       " 'B*44:23',\n",
       " 'B*44:237',\n",
       " 'B*44:314',\n",
       " 'B*44:328',\n",
       " 'B*44:333',\n",
       " 'B*44:345',\n",
       " 'B*44:438',\n",
       " 'B*44:448',\n",
       " 'B*44:449',\n",
       " 'B*44:52',\n",
       " 'B*44:56',\n",
       " 'B*44:58',\n",
       " 'B*44:61',\n",
       " 'B*46:07',\n",
       " 'B*46:41',\n",
       " 'B*46:55',\n",
       " 'B*46:79',\n",
       " 'B*49:19',\n",
       " 'B*49:60',\n",
       " 'B*50:72',\n",
       " 'B*51:110',\n",
       " 'B*51:118',\n",
       " 'B*51:149',\n",
       " 'B*51:178',\n",
       " 'B*51:184',\n",
       " 'B*51:235',\n",
       " 'B*51:245',\n",
       " 'B*51:27',\n",
       " 'B*51:273',\n",
       " 'B*51:287',\n",
       " 'B*51:306',\n",
       " 'B*51:313',\n",
       " 'B*51:318',\n",
       " 'B*51:41',\n",
       " 'B*51:44',\n",
       " 'B*51:98',\n",
       " 'B*52:49',\n",
       " 'B*52:89',\n",
       " 'B*52:96',\n",
       " 'B*53:48',\n",
       " 'B*54:05',\n",
       " 'B*54:08',\n",
       " 'B*55:55',\n",
       " 'B*55:89',\n",
       " 'B*56:19',\n",
       " 'B*56:28',\n",
       " 'B*56:38',\n",
       " 'B*57:122',\n",
       " 'B*57:28',\n",
       " 'B*58:10',\n",
       " 'B*58:17',\n",
       " 'B*58:39',\n",
       " 'B*58:72',\n",
       " 'B*58:93',\n",
       " 'B*58:94',\n",
       " 'B*59:10',\n",
       " 'B*81:04',\n",
       " 'C*01:111',\n",
       " 'C*01:117',\n",
       " 'C*01:137',\n",
       " 'C*01:143',\n",
       " 'C*01:145',\n",
       " 'C*01:171',\n",
       " 'C*01:37',\n",
       " 'C*01:56',\n",
       " 'C*01:69',\n",
       " 'C*01:86',\n",
       " 'C*01:98',\n",
       " 'C*02:105',\n",
       " 'C*02:121',\n",
       " 'C*02:135',\n",
       " 'C*02:165',\n",
       " 'C*02:192',\n",
       " 'C*02:38',\n",
       " 'C*02:52',\n",
       " 'C*02:92',\n",
       " 'C*03:121',\n",
       " 'C*03:189',\n",
       " 'C*03:201',\n",
       " 'C*03:208',\n",
       " 'C*03:229',\n",
       " 'C*03:23',\n",
       " 'C*03:265',\n",
       " 'C*03:277',\n",
       " 'C*03:316',\n",
       " 'C*03:318',\n",
       " 'C*03:323',\n",
       " 'C*03:363',\n",
       " 'C*03:377',\n",
       " 'C*03:391',\n",
       " 'C*03:392',\n",
       " 'C*03:396',\n",
       " 'C*03:444',\n",
       " 'C*03:445',\n",
       " 'C*03:446',\n",
       " 'C*03:447',\n",
       " 'C*03:449',\n",
       " 'C*03:462',\n",
       " 'C*03:463',\n",
       " 'C*03:508',\n",
       " 'C*03:509',\n",
       " 'C*03:510',\n",
       " 'C*03:511',\n",
       " 'C*03:531',\n",
       " 'C*04:105',\n",
       " 'C*04:115',\n",
       " 'C*04:123',\n",
       " 'C*04:170',\n",
       " 'C*04:173',\n",
       " 'C*04:191',\n",
       " 'C*04:203',\n",
       " 'C*04:205',\n",
       " 'C*04:215',\n",
       " 'C*04:217',\n",
       " 'C*04:225',\n",
       " 'C*04:233',\n",
       " 'C*04:234',\n",
       " 'C*04:236',\n",
       " 'C*04:253',\n",
       " 'C*04:255',\n",
       " 'C*04:279',\n",
       " 'C*04:300',\n",
       " 'C*04:305',\n",
       " 'C*04:309',\n",
       " 'C*04:349',\n",
       " 'C*04:350',\n",
       " 'C*04:362',\n",
       " 'C*04:364',\n",
       " 'C*04:365',\n",
       " 'C*04:369',\n",
       " 'C*04:371',\n",
       " 'C*04:374',\n",
       " 'C*04:377',\n",
       " 'C*04:385',\n",
       " 'C*04:396',\n",
       " 'C*04:410',\n",
       " 'C*04:417',\n",
       " 'C*04:88',\n",
       " 'C*04:93',\n",
       " 'C*04:95',\n",
       " 'C*05:07',\n",
       " 'C*05:113',\n",
       " 'C*05:128',\n",
       " 'C*05:154',\n",
       " 'C*05:169',\n",
       " 'C*05:175',\n",
       " 'C*05:180',\n",
       " 'C*05:208',\n",
       " 'C*05:213',\n",
       " 'C*05:244',\n",
       " 'C*05:48',\n",
       " 'C*05:91',\n",
       " 'C*05:92',\n",
       " 'C*05:99',\n",
       " 'C*06:116',\n",
       " 'C*06:128',\n",
       " 'C*06:134',\n",
       " 'C*06:152',\n",
       " 'C*06:16',\n",
       " 'C*06:171',\n",
       " 'C*06:175',\n",
       " 'C*06:208',\n",
       " 'C*06:215',\n",
       " 'C*06:220',\n",
       " 'C*06:257',\n",
       " 'C*06:259',\n",
       " 'C*06:263',\n",
       " 'C*06:267',\n",
       " 'C*06:281',\n",
       " 'C*06:301',\n",
       " 'C*06:309',\n",
       " 'C*06:49',\n",
       " 'C*06:79',\n",
       " 'C*07:104',\n",
       " 'C*07:152',\n",
       " 'C*07:164',\n",
       " 'C*07:191',\n",
       " 'C*07:198',\n",
       " 'C*07:227',\n",
       " 'C*07:264',\n",
       " 'C*07:32',\n",
       " 'C*07:329',\n",
       " 'C*07:33',\n",
       " 'C*07:347',\n",
       " 'C*07:393',\n",
       " 'C*07:437',\n",
       " 'C*07:451',\n",
       " 'C*07:452',\n",
       " 'C*07:476',\n",
       " 'C*07:483',\n",
       " 'C*07:484',\n",
       " 'C*07:491',\n",
       " 'C*07:507',\n",
       " 'C*07:55',\n",
       " 'C*07:551',\n",
       " 'C*07:600',\n",
       " 'C*07:603',\n",
       " 'C*07:61',\n",
       " 'C*07:633',\n",
       " 'C*07:672',\n",
       " 'C*07:690',\n",
       " 'C*07:702',\n",
       " 'C*07:726',\n",
       " 'C*07:733',\n",
       " 'C*07:745',\n",
       " 'C*07:746',\n",
       " 'C*07:747',\n",
       " 'C*07:749',\n",
       " 'C*07:750',\n",
       " 'C*07:751',\n",
       " 'C*07:752',\n",
       " 'C*07:753',\n",
       " 'C*07:754',\n",
       " 'C*07:770',\n",
       " 'C*07:773',\n",
       " 'C*07:787',\n",
       " 'C*07:804',\n",
       " 'C*07:820',\n",
       " 'C*07:821',\n",
       " 'C*07:839',\n",
       " 'C*07:849',\n",
       " 'C*07:856',\n",
       " 'C*07:863',\n",
       " 'C*07:881',\n",
       " 'C*07:889',\n",
       " 'C*07:98',\n",
       " 'C*08:121',\n",
       " 'C*08:127',\n",
       " 'C*08:129',\n",
       " 'C*08:130',\n",
       " 'C*08:161',\n",
       " 'C*08:173',\n",
       " 'C*08:180',\n",
       " 'C*08:181',\n",
       " 'C*08:208',\n",
       " 'C*08:214',\n",
       " 'C*08:26',\n",
       " 'C*08:36',\n",
       " 'C*08:55',\n",
       " 'C*08:88',\n",
       " 'C*08:89',\n",
       " 'C*12:104',\n",
       " 'C*12:105',\n",
       " 'C*12:148',\n",
       " 'C*12:219',\n",
       " 'C*12:232',\n",
       " 'C*12:236',\n",
       " 'C*12:270',\n",
       " 'C*12:274',\n",
       " 'C*12:311',\n",
       " 'C*12:327',\n",
       " 'C*12:329',\n",
       " 'C*12:39',\n",
       " 'C*12:46',\n",
       " 'C*12:80',\n",
       " 'C*12:84',\n",
       " 'C*14:07',\n",
       " 'C*14:21',\n",
       " 'C*14:35',\n",
       " 'C*14:47',\n",
       " 'C*14:93',\n",
       " 'C*14:97',\n",
       " 'C*14:99',\n",
       " 'C*15:115',\n",
       " 'C*15:122',\n",
       " 'C*15:145',\n",
       " 'C*15:156',\n",
       " 'C*15:177',\n",
       " 'C*15:185',\n",
       " 'C*15:188',\n",
       " 'C*15:189',\n",
       " 'C*15:216',\n",
       " 'C*15:92',\n",
       " 'C*15:95',\n",
       " 'C*16:123',\n",
       " 'C*16:132',\n",
       " 'C*16:30',\n",
       " 'C*16:77',\n",
       " 'C*16:89',\n",
       " 'C*17:27',\n",
       " 'C*18:07',\n",
       " 'DQB1*02:129',\n",
       " 'DQB1*02:132',\n",
       " 'DQB1*02:134',\n",
       " 'DQB1*02:162',\n",
       " 'DQB1*02:167',\n",
       " 'DQB1*02:177',\n",
       " 'DQB1*02:18',\n",
       " 'DQB1*02:20',\n",
       " 'DQB1*02:58',\n",
       " 'DQB1*02:67',\n",
       " 'DQB1*03:118',\n",
       " 'DQB1*03:213',\n",
       " 'DQB1*03:237',\n",
       " 'DQB1*03:269',\n",
       " 'DQB1*03:282',\n",
       " 'DQB1*03:303',\n",
       " 'DQB1*03:334',\n",
       " 'DQB1*03:339',\n",
       " 'DQB1*03:354',\n",
       " 'DQB1*03:356',\n",
       " 'DQB1*03:357',\n",
       " 'DQB1*03:399',\n",
       " 'DQB1*03:407',\n",
       " 'DQB1*03:411',\n",
       " 'DQB1*03:427',\n",
       " 'DQB1*03:440',\n",
       " 'DQB1*03:66',\n",
       " 'DQB1*03:90',\n",
       " 'DQB1*03:95',\n",
       " 'DQB1*04:25',\n",
       " 'DQB1*04:36',\n",
       " 'DQB1*04:73',\n",
       " 'DQB1*05:110',\n",
       " 'DQB1*05:128',\n",
       " 'DQB1*05:206',\n",
       " 'DQB1*05:208',\n",
       " 'DQB1*05:215',\n",
       " 'DQB1*05:224',\n",
       " 'DQB1*05:235',\n",
       " 'DQB1*05:236',\n",
       " 'DQB1*06:112',\n",
       " 'DQB1*06:144',\n",
       " 'DQB1*06:158',\n",
       " 'DQB1*06:179',\n",
       " 'DQB1*06:193',\n",
       " 'DQB1*06:252',\n",
       " 'DQB1*06:26',\n",
       " 'DQB1*06:303',\n",
       " 'DQB1*06:306',\n",
       " 'DQB1*06:341',\n",
       " 'DQB1*06:345',\n",
       " 'DQB1*06:379',\n",
       " 'DQB1*06:54',\n",
       " 'DQB1*06:75',\n",
       " 'DQB1*06:77',\n",
       " 'DRB1*01:33',\n",
       " 'DRB1*01:39',\n",
       " 'DRB1*01:40',\n",
       " 'DRB1*01:52',\n",
       " 'DRB1*01:62',\n",
       " 'DRB1*01:68',\n",
       " 'DRB1*03:156',\n",
       " 'DRB1*03:174',\n",
       " 'DRB1*03:67',\n",
       " 'DRB1*03:68',\n",
       " 'DRB1*04:119',\n",
       " 'DRB1*04:120',\n",
       " 'DRB1*04:142',\n",
       " 'DRB1*04:157',\n",
       " 'DRB1*04:158',\n",
       " 'DRB1*04:178',\n",
       " 'DRB1*04:186',\n",
       " 'DRB1*04:212',\n",
       " 'DRB1*04:214',\n",
       " 'DRB1*04:247',\n",
       " 'DRB1*04:264',\n",
       " 'DRB1*04:267',\n",
       " 'DRB1*04:280',\n",
       " 'DRB1*04:299',\n",
       " 'DRB1*04:312',\n",
       " 'DRB1*04:81',\n",
       " 'DRB1*04:94',\n",
       " 'DRB1*07:10',\n",
       " 'DRB1*07:101',\n",
       " 'DRB1*07:118',\n",
       " 'DRB1*07:26',\n",
       " 'DRB1*07:58',\n",
       " 'DRB1*07:68',\n",
       " 'DRB1*07:87',\n",
       " 'DRB1*08:60',\n",
       " 'DRB1*08:78',\n",
       " 'DRB1*08:89',\n",
       " 'DRB1*09:37',\n",
       " 'DRB1*11:169',\n",
       " 'DRB1*11:217',\n",
       " 'DRB1*11:246',\n",
       " 'DRB1*12:24',\n",
       " 'DRB1*12:31',\n",
       " 'DRB1*12:60',\n",
       " 'DRB1*12:74',\n",
       " 'DRB1*13:113',\n",
       " 'DRB1*13:137',\n",
       " 'DRB1*13:142',\n",
       " 'DRB1*13:185',\n",
       " 'DRB1*13:200',\n",
       " 'DRB1*13:249',\n",
       " 'DRB1*13:252',\n",
       " 'DRB1*13:289',\n",
       " 'DRB1*13:295',\n",
       " 'DRB1*14:137',\n",
       " 'DRB1*14:152',\n",
       " 'DRB1*14:166',\n",
       " 'DRB1*14:188',\n",
       " 'DRB1*14:195',\n",
       " 'DRB1*14:197',\n",
       " 'DRB1*14:222',\n",
       " 'DRB1*14:92',\n",
       " 'DRB1*15:113',\n",
       " 'DRB1*15:115',\n",
       " 'DRB1*15:129',\n",
       " 'DRB1*15:134',\n",
       " 'DRB1*15:137',\n",
       " 'DRB1*15:138',\n",
       " 'DRB1*15:148',\n",
       " 'DRB1*15:159',\n",
       " 'DRB1*15:17',\n",
       " 'DRB1*15:176',\n",
       " 'DRB1*15:183',\n",
       " 'DRB1*15:50',\n",
       " 'DRB1*15:80',\n",
       " 'DRB1*16:13',\n",
       " 'DRB1*16:21',\n",
       " 'DRB1*16:41',\n",
       " 'DRB1*16:55',\n",
       " 'DRB1*16:62',\n",
       " 'DRB1*16:63'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the difference between these two sets:\n",
    "set(unique_p_alleles_set).difference(set(p_group_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this site: https://www.ebi.ac.uk/cgi-bin/ipd/imgt/hla/allele.cgi\n",
    "found out, that the alleles not included are null alleles, and that they therefore should be included, when comparing to the number of two-field and g group resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of evaxion group alleles:\n",
    "Using the info found before (about null alleles not being included) I use this method for finding the number of e-group alleles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12433"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_e_alleles_set = set()\n",
    "for allele in list(set(g_group_values)):\n",
    "    \n",
    "    unique_e_alleles_set.add(convert_to_e_group(allele))\n",
    "\n",
    "len(list(unique_e_alleles_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g_group' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0d8496b3e714>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mg_group\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'g_group' is not defined"
     ]
    }
   ],
   "source": [
    "g_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 0\n",
    "\n",
    "\n",
    "for allele in list(set(g_group_values)):\n",
    "    \n",
    "    allele_two_field = make_two_field(allele)\n",
    "    print(allele, allele_two_field, convert_to_g_group(allele))\n",
    "    \n",
    "    if allele_two_field == convert_to_g_group(allele):\n",
    "        overlap += 1\n",
    "\n",
    "print(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_g_group('C*01:02:40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of null alleles, not in a P group\n",
    "Results taken from: Result parsing (null alleles)\n",
    "\t\t\t\t\tPlotting (number of mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot = 8290\n",
    "n_hlaI = 4974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P group: % of errors: 1.0355029585798818 %\n",
      "NetMHCseq: % of errors: 1.0794140323824208 %\n",
      "% of total: 0.16887816646562123 %\n"
     ]
    }
   ],
   "source": [
    "#Kourami\n",
    "\n",
    "count = 14\n",
    "mistakes_p = 1352\n",
    "mistakes_netmhc = 1297\n",
    "\n",
    "#Percentage of errors:\n",
    "print(\"P group: % of errors:\", count/mistakes_p * 100, \"%\")\n",
    "print(\"NetMHCseq: % of errors:\", count/mistakes_netmhc * 100, \"%\")\n",
    "\n",
    "#Percentage of total:\n",
    "print(\"% of total:\", count/n_tot * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HG00463\tC*08:36\n",
    "HG00501\tA*24:86\n",
    "HG00501\tA*24:86\n",
    "HG00689\tC*08:36\n",
    "HG01061\tDRB1*04:178\n",
    "HG01353\tA*24:86\n",
    "NA06986\tDQB1*02:18\n",
    "NA19307\tDRB1*15:17\n",
    "NA19359\tDRB1*15:17\n",
    "NA19384\tDRB1*15:17\n",
    "NA19397\tDRB1*15:17\n",
    "NA20289\tA*30:73\n",
    "NA20512\tDRB1*15:17\n",
    "NA20534\tA*30:73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P group: % of errors: 2.26537216828479 %\n",
      "NetMHCseq: % of errors: 2.6022304832713754 %\n",
      "% of total: 0.08443908323281062 %\n"
     ]
    }
   ],
   "source": [
    "#HLA-LA\n",
    "\n",
    "count = 7\n",
    "mistakes_p = 309\n",
    "mistakes_netmhc = 269\n",
    "\n",
    "#Percentage of errors:\n",
    "print(\"P group: % of errors:\", count/mistakes_p * 100, \"%\")\n",
    "print(\"NetMHCseq: % of errors:\", count/mistakes_netmhc * 100, \"%\")\n",
    "\n",
    "#Percentage of total:\n",
    "print(\"% of total:\", count/n_tot * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "HG00240\tA*02:250\n",
    "HG00310\tA*03:03\n",
    "HG00327\tA*68:18\n",
    "HG00407\tB*40:265\n",
    "HG00620\tDQB1*03:118\n",
    "HG01438\tA*03:36\n",
    "NA20799\tA*03:03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optitype\n",
    "\n",
    "count: 0\n",
    "mistakes at P group level: 67\n",
    "mistakes at NetMHCseq group level: 56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P group: % of errors: 1.7897091722595078 %\n",
      "NetMHCseq: % of errors: 1.911589008363202 %\n",
      "% of total: 0.19300361881785283 %\n"
     ]
    }
   ],
   "source": [
    "#Hisatgenotype\n",
    "\n",
    "count = 16\n",
    "mistakes_p = 894\n",
    "mistakes_netmhc = 837\n",
    "\n",
    "#Percentage of errors:\n",
    "print(\"P group: % of errors:\", count/mistakes_p * 100, \"%\")\n",
    "print(\"NetMHCseq: % of errors:\", count/mistakes_netmhc * 100, \"%\")\n",
    "\n",
    "#Percentage of total:\n",
    "print(\"% of total:\", count/n_tot * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "HG00109\tDQB1*06:112\n",
    "HG00120\tA*01:16\n",
    "HG00272\tA*01:16\n",
    "HG00310\tDQB1*06:112\n",
    "HG00332\tA*02:321\n",
    "HG00346\tDQB1*06:112\n",
    "HG00384\tA*03:11\n",
    "HG00403\tA*02:321\n",
    "HG00463\tDQB1*03:95\n",
    "HG00500\tC*01:117\n",
    "HG00533\tDQB1*06:112\n",
    "HG00640\tC*05:07\n",
    "HG01061\tC*04:217\n",
    "NA19473\tC*04:105\n",
    "NA19657\tA*01:16\n",
    "NA20757\tA*02:321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P group: % of errors: 0.812807881773399 %\n",
      "NetMHCseq: % of errors: 0.8250000000000001 %\n",
      "% of total: 0.3980699638118214 %\n"
     ]
    }
   ],
   "source": [
    "#STC-seq\n",
    "\n",
    "count = 33\n",
    "mistakes_p = 4060\n",
    "mistakes_netmhc = 4000\n",
    "\n",
    "#Percentage of errors:\n",
    "print(\"P group: % of errors:\", count/mistakes_p * 100, \"%\")\n",
    "print(\"NetMHCseq: % of errors:\", count/mistakes_netmhc * 100, \"%\")\n",
    "\n",
    "#Percentage of total:\n",
    "print(\"% of total:\", count/n_tot * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "HG00096\tA*01:11\n",
    "HG00127\tA*26:127\n",
    "HG00131\tC*06:116\n",
    "HG00131\tC*06:116\n",
    "HG00142\tC*06:116\n",
    "HG00245\tDQB1*03:90\n",
    "HG00367\tC*06:116\n",
    "HG00372\tDQB1*06:193\n",
    "HG00451\tA*11:251\n",
    "HG00475\tDQB1*06:54\n",
    "HG00557\tC*06:116\n",
    "HG01066\tDQB1*02:18\n",
    "HG01110\tC*04:217\n",
    "HG01110\tC*06:116\n",
    "HG01111\tB*35:145\n",
    "HG01187\tC*06:116\n",
    "HG01197\tC*06:116\n",
    "HG01256\tC*07:393\n",
    "NA06985\tC*06:116\n",
    "NA06986\tDQB1*02:18\n",
    "NA12046\tC*06:116\n",
    "NA12046\tC*06:116\n",
    "NA12286\tC*06:116\n",
    "NA12286\tC*06:116\n",
    "NA19309\tC*06:116\n",
    "NA19311\tB*14:41\n",
    "NA19318\tB*07:251\n",
    "NA19446\tC*06:116\n",
    "NA19463\tC*06:116\n",
    "NA19747\tB*14:41\n",
    "NA20755\tB*41:45\n",
    "NA20800\tB*37:42\n",
    "NA20800\tB*37:42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weird G group conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make dict for G-type conversion\n",
    "\n",
    "g_group_filepath = gold_standard_path + 'g_group_resolution.txt'\n",
    "\n",
    "g_group_dict = dict()\n",
    "\n",
    "\n",
    "#Make conversion from full allele names to G groups\n",
    "with open(g_group_filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        #If several alleles map to the same one, they are separated by a \"/\"\n",
    "        if line[0] != '#':\n",
    "            gene = line.split('*')[0]\n",
    "            \n",
    "            #Only register the valid alleles:\n",
    "            if gene in ['A', 'B', 'C', 'DRB1', 'DQB1']:\n",
    "                        \n",
    "                #find full G type for entry - differs depending on, whether there are 1 or multiple entries in the group.\n",
    "                if \"/\" in line:\n",
    "                    g_group_full = gene + \"*\" + line.split(';')[-1][:-1]\n",
    "                else:\n",
    "                    g_group_full = gene + \"*\" + line.split(';')[-2]\n",
    "\n",
    "                #For full dict (parallel to four-field dict)\n",
    "                #Read the rest of the alleles and clean up the front and end part\n",
    "                synonymous_alleles = line.split('/')\n",
    "                synonymous_alleles[0] = synonymous_alleles[0].split(';')[1]\n",
    "                synonymous_alleles[-1] = synonymous_alleles[-1].split(';')[0]\n",
    "                \n",
    "                #Add \"gene*\" in front of all alleles:\n",
    "                for i in range(len(synonymous_alleles)):\n",
    "                    synonymous_alleles[i] = gene + \"*\" + synonymous_alleles[i]\n",
    "                \n",
    "                #Add the group itself to the list, so that tools predicting in G-type resolution can be converted in similar fashion\n",
    "                synonynous_alleles = synonymous_alleles.append(g_group_full)\n",
    "                \n",
    "                #Remove duplicates\n",
    "                synonymous_allels_unique = sorted(list(set(synonymous_alleles)), reverse=True)\n",
    "                \n",
    "                #Add key in dict for each of the unique entries:\n",
    "                for allele in synonymous_allels_unique :                    \n",
    "                    g_group_dict[allele] = g_group_full\n",
    "\n",
    "\n",
    "                    \n",
    "print(\"Ambiguities in two-field resolution:\")\n",
    "print(\"Allele\", \"Primary G-group\", \"Alternative group\", sep = \"\\t\")\n",
    "#Add entries for 4-field and 6-field resolution typings, not already found in g_group_dict.\n",
    "#This is done after, in order to not overwrite ambiguous G-group mappings such as C*02:02,\n",
    "#which could map to C*02:02:01 or C*02:10:01G depending on the full typing.\n",
    "with open(g_group_filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        #If several alleles map to the same one, they are separated by a \"/\"\n",
    "        if line[0] != '#':\n",
    "            gene = line.split('*')[0]\n",
    "            \n",
    "            #Only register the valid alleles:\n",
    "            if gene in ['A', 'B', 'C', 'DRB1', 'DQB1']:                \n",
    "                \n",
    "                if \"/\" in line:\n",
    "                    g_group_full = gene + \"*\" + line.split(';')[-1][:-1]\n",
    "                else:\n",
    "                    g_group_full = gene + \"*\" + line.split(';')[-2]\n",
    "\n",
    "                #Add to four field dict (Parralel to the full dict)\n",
    "                synonymous_alleles_two_field = line.split('/')\n",
    "                synonymous_alleles_two_field[0] = synonymous_alleles_two_field[0].split(';')[1]\n",
    "                synonymous_alleles_two_field[-1] = synonymous_alleles_two_field[-1].split(';')[0]\n",
    "                                \n",
    "                #Convert all alleles to four field resolution for four field typing:\n",
    "                for i in range(len(synonymous_alleles_two_field)):\n",
    "                    synonymous_alleles_two_field[i] = gene + \"*\" + synonymous_alleles_two_field[i]\n",
    "                    synonymous_alleles_two_field[i] = make_two_field(synonymous_alleles_two_field[i])\n",
    "\n",
    "                #Remove duplicates when converting to four field:\n",
    "                synonymous_allels_unique_two_field = sorted(list(set(synonymous_alleles_two_field)), reverse=True)\n",
    "                \n",
    "                #Add key in dict for each of the unique entries:\n",
    "                for allele in synonymous_allels_unique_two_field:                    \n",
    "                    \n",
    "                    #Only add entries, which aren't already in the dict\n",
    "                    if (allele in g_group_dict.keys()):\n",
    "                        \n",
    "                        #For two-field: Check for ambiguities in the G-type conversion e.g. C*02:02:02G and C*02:10:01G have same exon sequence for exon 2 and 3\n",
    "                        #Print the ambiguity - because of sort, nothing is added. two-field-typed-allele is kept in the group\n",
    "                        if (g_group_dict[allele] != g_group_full) and (\"/\" in line):\n",
    "                            print(\"two_field_res\", allele, g_group_dict[allele], g_group_full, sep=', ')\n",
    "                            \n",
    "                    else:\n",
    "                        g_group_dict[allele] = g_group_full\n",
    "                \n",
    "                #Add to six field dict (Parralel to the full dict)\n",
    "                synonymous_alleles_three_field = line.split('/')\n",
    "                synonymous_alleles_three_field[0] = synonymous_alleles_three_field[0].split(';')[1]\n",
    "                synonymous_alleles_three_field[-1] = synonymous_alleles_three_field[-1].split(';')[0]\n",
    "                \n",
    "                  #Convert all alleles to six field resolution for six field typing:\n",
    "                for i in range(len(synonymous_alleles_three_field)):\n",
    "                    synonymous_alleles_three_field[i] = gene + \"*\" + synonymous_alleles_three_field[i]\n",
    "                    synonymous_alleles_three_field[i] = make_three_field(synonymous_alleles_three_field[i])\n",
    "                    \n",
    "                \n",
    "                synonymous_alleles_three_field = [i for i in synonymous_alleles_three_field if i != None]\n",
    "                #Remove duplicates when converting to six field:\n",
    "                synonymous_allels_unique_three_field = sorted(list(set(synonymous_alleles_three_field)), reverse=True)\n",
    "                \n",
    "                #Add key in dict for each of the unique entries:\n",
    "                for allele in synonymous_allels_unique_three_field:                    \n",
    "                    \n",
    "                    #Only add entries, which aren't already in the dict\n",
    "                    if (allele in g_group_dict.keys()):\n",
    "                        \n",
    "                        #For six-field: Check for ambiguities in the G-type conversion e.g. C*02:02:02G and C*02:10:01G have same exon sequence for exon 2 and 3\n",
    "                        #Print the ambiguity - because of sort, nothing is added. six-field-typed-allele is kept in the group\n",
    "                        if (g_group_dict[allele] != g_group_full) and (\"/\" in line):\n",
    "                            print(\"three_field_res:\", allele, g_group_dict[allele], g_group_full, sep=', ')\n",
    "                            \n",
    "                    else:\n",
    "                        g_group_dict[allele] = g_group_full\n",
    "\n",
    "                \n",
    "                \n",
    "                    \n",
    "#Make G type conversion function using g_group_dict\n",
    "def convert_to_g_group(allele):\n",
    "\n",
    "    if allele in g_group_dict.keys():\n",
    "        allele_g_group = g_group_dict[allele]\n",
    "    else:\n",
    "        allele_g_group = make_two_field(allele)\n",
    "        \n",
    "    return allele_g_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
